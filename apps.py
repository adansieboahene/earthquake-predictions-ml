# -*- coding: utf-8 -*-
"""apps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NdrCSsUcB-TiNHNQnE-Yo5C8luBIJLvy
"""

import streamlit as st
import pandas as pd
from sklearn.cluster import KMeans
import pydeck as pdk

# Page configuration
st.set_page_config(
    page_title="Earthquake Severity and Regional Risk Dashboard",
    layout="wide"
)

st.title("Earthquake Severity and Regional Risk Dashboard")
st.write(
    "This dashboard visualizes earthquake severity and regional risk "
    "using a representative sampled dataset derived from historical "
    "USGS seismic records from 2000 to 2024."
)

# Load data
@st.cache_data
def load_data():
    df = pd.read_csv("earthquake_sample_2000_2024.csv")

    df["time"] = pd.to_datetime(df["time"])
    df["year"] = df["year"].astype(int)
    df["severity"] = df["severity"].astype(int)

    return df

df = load_data()

# Sidebar filters
st.sidebar.header("Filters")

year_range = st.sidebar.slider(
    "Select year range",
    int(df["year"].min()),
    int(df["year"].max()),
    (2000, 2024)
)

min_magnitude = st.sidebar.slider(
    "Minimum magnitude",
    float(df["mag"].min()),
    float(df["mag"].max()),
    2.5
)

filtered_df = df[
    (df["year"] >= year_range[0]) &
    (df["year"] <= year_range[1]) &
    (df["mag"] >= min_magnitude)
].copy()

# Summary statistics
st.subheader("Summary Statistics")

col1, col2, col3 = st.columns(3)
col1.metric("Total Earthquakes", len(filtered_df))
col2.metric(
    "High Severity Percentage",
    round(filtered_df["severity"].mean() * 100, 2)
)
col3.metric(
    "Average Magnitude",
    round(filtered_df["mag"].mean(), 2)
)

# Earthquake event map
st.subheader("Earthquake Event Map")

map_df = filtered_df.copy()
map_df["color"] = map_df["severity"].apply(
    lambda x: [255, 0, 0] if x == 1 else [0, 0, 255]
)

layer = pdk.Layer(
    "ScatterplotLayer",
    data=map_df,
    get_position=["longitude", "latitude"],
    get_radius=50000,
    get_color="color",
    pickable=True
)

view_state = pdk.ViewState(
    latitude=map_df["latitude"].mean(),
    longitude=map_df["longitude"].mean(),
    zoom=1
)

st.pydeck_chart(
    pdk.Deck(
        layers=[layer],
        initial_view_state=view_state,
        tooltip={
            "text": "Magnitude: {mag}\nDepth: {depth} km"
        }
    )
)

# Regional earthquake risk classification
st.subheader("Regional Earthquake Risk Classification")

coords = filtered_df[["latitude", "longitude"]]

kmeans = KMeans(n_clusters=20, random_state=42)
filtered_df["region"] = kmeans.fit_predict(coords)

region_df = filtered_df.groupby("region").agg(
    earthquake_count=("mag", "count"),
    avg_magnitude=("mag", "mean"),
    high_severity_ratio=("severity", "mean")
).reset_index()

def assign_risk(ratio):
    if ratio < 0.2:
        return "Low"
    elif ratio < 0.5:
        return "Medium"
    else:
        return "High"

region_df["risk_level"] = region_df["high_severity_ratio"].apply(assign_risk)

st.dataframe(region_df, use_container_width=True)

# Risk distribution chart
st.subheader("Risk Level Distribution")

risk_counts = region_df["risk_level"].value_counts()
st.bar_chart(risk_counts)

# Disclaimer
st.caption(
    "This prototype visualizes historical earthquake severity and regional risk "
    "using a representative sampled dataset. It does not provide real-time "
    "prediction or early warning functionality."
)